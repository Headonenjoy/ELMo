{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Visualizing ELMo Contextual Vectors](https://towardsdatascience.com/visualizing-elmo-contextual-vectors-94168768fdaa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 让我们尝试使用ELMo模型生成上下文向量，并使用PCA将向量投影到2D空间进行可视化。 在ELMo论文中，有3层字嵌入，第0层是基于字符的上下文无关层，后面是两个Bi-LSTM层。 作者凭经验证明，从第一个Bi-LSTM层生成的单词向量可以更好地捕获语法，第二层可以更好地捕获语义。 我们将为具有多种x形态的 - bank，work和plant的三个单词可视化第1层和第2层上下文向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let’s try using the ELMo model to generate contextual vectors and using PCA to project the vectors to a 2D space for visualization. In the ELMo paper, there are 3 layers of word embedding, layer zero is the character-based context independent layer, followed by two Bi-LSTM layers. The authors have empirically shown that the word vectors generated from the first Bi-LSTM layer can better capture the syntax, and the second layer can capture the semantics better. We will visualize both layer 1 and layer 2 contextual vectors for three words that have multiple senses— bank, work, and plant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.elmo import batch_to_ids\n",
    "from allennlp.commands.elmo import ElmoEmbedder\n",
    "\n",
    "#dowload options_file and weight_file files form https://allennlp.org/elmo\n",
    "options_file = \"/home/b418/jupyter_workspace/yuanxiao/elmo_data/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json\"\n",
    "weight_file = \"/home/b418/jupyter_workspace/yuanxiao/elmo_data/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5\"\n",
    "\n",
    "elmo = ElmoEmbedder(options_file, weight_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Elmo:\n",
    "    def __init__(self, options_file, weight_file):\n",
    "        self.elmo = ElmoEmbedder(options_file, weight_file)\n",
    "\n",
    "    def get_elmo_vector(self, tokens, layer):\n",
    "        vectors = self.elmo.embed_sentence(tokens)\n",
    "        X = []\n",
    "        for vector in vectors[layer]:\n",
    "            X.append(vector)\n",
    "\n",
    "        X = np.array(X)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dim_reduction(X, n):\n",
    "    pca = PCA(n_components=n)\n",
    "    results = pca.fit_transform(X)\n",
    "    print(\"size of reduced X: {}\".format(results.shape))\n",
    "\n",
    "    for i, ratio in enumerate(pca.explained_variance_ratio_):\n",
    "        print(\"Variance retained ratio of PCA-{}: {}\".format(i+1, ratio))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(word, token_list, reduced_X, file_name, title):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # plot ELMo vectors\n",
    "    i = 0\n",
    "    for j, token in enumerate(token_list):\n",
    "        color = pick_color(j)\n",
    "        for _, w in enumerate(token):\n",
    "\n",
    "            # only plot the word of interest\n",
    "            if w.lower() in [word, word + 's', word + 'ing', word + 'ed']:\n",
    "                ax.plot(reduced_X[i, 0], reduced_X[i, 1], color)\n",
    "            i += 1\n",
    "\n",
    "    tokens = []\n",
    "    for token in token_list:\n",
    "        tokens += token\n",
    "\n",
    "    # annotate point\n",
    "    k = 0\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token.lower() in [word, word + 's', word + 'ing', word + 'ed']:\n",
    "            text = ' '.join(token_list[k])\n",
    "\n",
    "            # bold the word of interest in the sentence\n",
    "            text = text.replace(token, r\"$\\bf{\" + token + \"}$\")\n",
    "\n",
    "            plt.annotate(text, xy=(reduced_X[i, 0], reduced_X[i, 1]))\n",
    "            k += 1\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"PCA 1\")\n",
    "    ax.set_ylabel(\"PCA 2\")\n",
    "    fig.savefig(file_name, bbox_inches=\"tight\")\n",
    "\n",
    "    print(\"{} saved\\n\".format(file_name))\n",
    "\n",
    "\n",
    "def pick_color(i):\n",
    "    if i == 0:\n",
    "        color = 'ro'\n",
    "    elif i == 1:\n",
    "        color = 'bo'\n",
    "    elif i == 2:\n",
    "        color = 'yo'\n",
    "    elif i == 3:\n",
    "        color = 'go'\n",
    "    else:\n",
    "        color = 'co'\n",
    "    return color\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visualizing word bank using ELMo layer 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b418/anaconda3/envs/yuanxiao/lib/python3.6/site-packages/allennlp/nn/util.py:149: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  index_range = sequence_lengths.new_tensor(torch.arange(0, len(sequence_lengths)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of reduced X: (37, 2)\n",
      "Variance retained ratio of PCA-1: 0.21842965483665466\n",
      "Variance retained ratio of PCA-2: 0.07475615292787552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bank_elmo_layer_1.png saved\n",
      "\n",
      "visualizing word work using ELMo layer 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b418/anaconda3/envs/yuanxiao/lib/python3.6/site-packages/allennlp/nn/util.py:149: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  index_range = sequence_lengths.new_tensor(torch.arange(0, len(sequence_lengths)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of reduced X: (35, 2)\n",
      "Variance retained ratio of PCA-1: 0.0917154923081398\n",
      "Variance retained ratio of PCA-2: 0.08404156565666199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work_elmo_layer_1.png saved\n",
      "\n",
      "visualizing word plant using ELMo layer 1\n",
      "size of reduced X: (47, 2)\n",
      "Variance retained ratio of PCA-1: 0.09630362689495087\n",
      "Variance retained ratio of PCA-2: 0.06646716594696045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plant_elmo_layer_1.png saved\n",
      "\n",
      "visualizing word bank using ELMo layer 2\n",
      "size of reduced X: (37, 2)\n",
      "Variance retained ratio of PCA-1: 0.12367216497659683\n",
      "Variance retained ratio of PCA-2: 0.09037613123655319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bank_elmo_layer_2.png saved\n",
      "\n",
      "visualizing word work using ELMo layer 2\n",
      "size of reduced X: (35, 2)\n",
      "Variance retained ratio of PCA-1: 0.09765800833702087\n",
      "Variance retained ratio of PCA-2: 0.07844914495944977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work_elmo_layer_2.png saved\n",
      "\n",
      "visualizing word plant using ELMo layer 2\n",
      "size of reduced X: (47, 2)\n",
      "Variance retained ratio of PCA-1: 0.09669843316078186\n",
      "Variance retained ratio of PCA-2: 0.08065589517354965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plant_elmo_layer_2.png saved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Elmo(options_file, weight_file)\n",
    "\n",
    "banks = OrderedDict()\n",
    "banks[0] = \"One can deposit money at the bank\"\n",
    "banks[1] = \"He had a nice walk along the river bank\"\n",
    "banks[2] = \"I withdrew cash from the bank\"\n",
    "banks[3] = \"The river bank was not clean\"\n",
    "banks[4] = \"My wife and I have a joint bank account\"\n",
    "\n",
    "works = OrderedDict()\n",
    "works[0] = \"I like this beautiful work by Andy Warhol\"\n",
    "works[1] = \"Employee works hard every day\"\n",
    "works[2] = \"My sister works at Starbucks\"\n",
    "works[3] = \"This amazing work was done in the early nineteenth century\"\n",
    "works[4] = \"Hundreds of people work in this building\"\n",
    "\n",
    "plants = OrderedDict()\n",
    "plants[0] = \"The gardener planted some trees in my yard\"\n",
    "plants[1] = \"I plan to plant a Joshua tree tomorrow\"\n",
    "plants[2] = \"My sister planted a seed and hopes it will grow to a tree\"\n",
    "plants[3] = \"This kind of plant only grows in the subtropical region\"\n",
    "plants[4] = \"Most of the plants will die without water\"\n",
    "\n",
    "words = {\n",
    "    \"bank\": banks,\n",
    "    \"work\": works,\n",
    "    \"plant\": plants\n",
    "}\n",
    "\n",
    "# contextual vectors for ELMo layer 1 and 2\n",
    "for layer in [1, 2]:\n",
    "    for word, sentences in words.items():\n",
    "        print(\"visualizing word {} using ELMo layer {}\".format(word, layer))\n",
    "        X = np.concatenate([model.get_elmo_vector(tokens=sentences[idx].split(),\n",
    "                                                  layer=layer)\n",
    "                            for idx, _ in enumerate(sentences)], axis=0)\n",
    "\n",
    "        # The first 2 principal components\n",
    "        X_reduce = dim_reduction(X=X, n=2)\n",
    "\n",
    "        token_list = []\n",
    "        for _, sentence in sentences.items():\n",
    "            token_list.append(sentence.split())\n",
    "\n",
    "        file_name = \"{}_elmo_layer_{}.png\".format(word, layer)\n",
    "        title = \"Layer {} ELMo vectors of the word {}\".format(layer, word)\n",
    "        plot(word, token_list, X_reduce, file_name, title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bank visualizing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ \"One can deposit money at the bank\"\n",
    "+ \"He had a nice walk along the river bank\"\n",
    "+ \"I withdrew cash from the bank\"\n",
    "+ \"The river bank was not clean\"\n",
    "+ \"My wife and I have a joint bank account\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](bank_elmo_layer_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](bank_elmo_layer_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## work visualizing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ \"I like this beautiful work by Andy Warhol\"\n",
    "+ \"Employee works hard every day\"\n",
    "+ \"My sister works at Starbucks\"\n",
    "+ \"This amazing work was done in the early nineteenth century\"\n",
    "+ \"Hundreds of people work in this building\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](work_elmo_layer_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](work_elmo_layer_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plant visualizing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ \"The gardener planted some trees in my yard\"\n",
    "+ \"I plan to plant a Joshua tree tomorrow\"\n",
    "+ \"My sister planted a seed and hopes it will grow to a tree\"\n",
    "+ \"This kind of plant only grows in the subtropical region\"\n",
    "+ \"Most of the plants will die without water\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](plant_elmo_layer_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](plant_elmo_layer_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ By using contextual vectors, a word has different word vectors depending on different contexts, and the words with the same sense will be close to each other in vector space! Contextual word vectors with the same sense will form a cluster. We can then calculate the cluster centroid of each sense, and use a simple 1-nearest neighbor approach to disambiguate word sense in a sentence.\n",
    "+ ELMo layer 2 word vectors with same sense form clear cluster and the distance between cluster centroid is larger than layer 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
